diff --git a/tiktoken/core.py b/tiktoken/core.py
index 6bc9736..1b95e06 100644
--- a/tiktoken/core.py
+++ b/tiktoken/core.py
@@ -76,12 +76,35 @@ class Encoding:
             text = text.encode("utf-16", "surrogatepass").decode("utf-16", "replace")
             return self._core_bpe.encode_ordinary(text)

+    def _create_cache_key(
+        self,
+        text: str,
+        allowed_special: Literal["all"] | AbstractSet[str],
+        disallowed_special: Literal["all"] | Collection[str]
+    ) -> tuple:
+        """Create a hashable cache key from the encode parameters."""
+        # Convert allowed_special to a frozenset if it's not "all"
+        if allowed_special == "all":
+            allowed_special_key = "all"
+        else:
+            allowed_special_key = frozenset(allowed_special)
+
+        # Convert disallowed_special to a frozenset if it's not "all"
+        if disallowed_special == "all":
+            disallowed_special_key = "all"
+        else:
+            disallowed_special_key = frozenset(disallowed_special)
+
+        # Return a tuple that can be used as a dictionary key
+        return (text, allowed_special_key, disallowed_special_key)
+
     def encode(
         self,
         text: str,
         *,
         allowed_special: Literal["all"] | AbstractSet[str] = set(),  # noqa: B006
         disallowed_special: Literal["all"] | Collection[str] = "all",
+        use_cache: bool = False,
     ) -> list[int]:
         """Encodes a string into tokens.

@@ -96,6 +119,7 @@ class Encoding:
           cause all text corresponding to special tokens to be encoded as natural text.
         - Setting `allowed_special` to "all" will cause this function to treat all text
           corresponding to special tokens to be encoded as special tokens.
+        - Setting `use_cache` to True will cache the results for faster repeated encoding.

         ```
         >>> enc.encode("hello world")
@@ -110,6 +134,13 @@ class Encoding:
         [27, 91, 437, 1659, 5239, 91, 29]
         ```
         """
+        # Check if we should use the cache and if this text is already cached
+        if use_cache:
+            cache_key = self._create_cache_key(text, allowed_special, disallowed_special)
+            cached_result = self.cache.get(cache_key)
+            if cached_result is not None:
+                return cached_result
+
         if allowed_special == "all":
             allowed_special = self.special_tokens_set
         if disallowed_special == "all":
@@ -121,7 +152,7 @@ class Encoding:
                 raise_disallowed_special_token(match.group())

         try:
-            return self._core_bpe.encode(text, allowed_special)
+            result = self._core_bpe.encode(text, allowed_special)
         except UnicodeEncodeError:
             # BPE operates on bytes, but the regex operates on unicode. If we pass a str that is
             # invalid UTF-8 to Rust, it will rightfully complain. Here we do a quick and dirty
@@ -130,7 +161,13 @@ class Encoding:
             # string, but given that this is input we want to support, maybe that's okay.
             # Also we use errors="replace" to handle weird things like lone surrogates.
             text = text.encode("utf-16", "surrogatepass").decode("utf-16", "replace")
-            return self._core_bpe.encode(text, allowed_special)
+            result = self._core_bpe.encode(text, allowed_special)
+
+        # Add to cache if use_cache is True
+        if use_cache:
+            self.cache[cache_key] = result
+
+        return result

     def encode_to_numpy(
         self,

