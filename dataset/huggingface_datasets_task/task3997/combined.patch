diff --git a/src/datasets/features/features.py b/src/datasets/features/features.py
index 6a0da6401..4aaf0aaea 100644
--- a/src/datasets/features/features.py
+++ b/src/datasets/features/features.py
@@ -20,7 +20,7 @@ import re
 import sys
 from collections.abc import Iterable
 from dataclasses import InitVar, _asdict_inner, dataclass, field, fields
-from functools import reduce
+from functools import reduce, wraps
 from operator import mul
 from typing import Any, ClassVar, Dict, List, Optional
 from typing import Sequence as Sequence_
@@ -1198,6 +1198,47 @@ def require_decoding(feature: FeatureType, ignore_decode_attribute: bool = False
         return hasattr(feature, "decode_example") and (feature.decode if not ignore_decode_attribute else True)
 
 
+_require_decoding_cache = {}
+def custom_require_decoding(feature: FeatureType, ignore_decode_attribute: bool = False, custom_criteria: Optional[callable] = None) -> bool:
+    """
+    Custom function to determine if a feature requires decoding based on custom criteria.
+    """
+    if custom_criteria and callable(custom_criteria):
+        # Use a unique identifier or type string for Audio or any feature type
+        feature_id = str(feature)  # You can also use feature.dtype or feature.__class__ for non-Audio features
+ 
+        if feature_id not in _require_decoding_cache:
+            # Cache the decoding requirement for this feature
+            _require_decoding_cache[feature_id] = custom_criteria(feature)
+ 
+        return _require_decoding_cache[feature_id]
+
+    # Fall back to the original require_decoding if no custom criteria provided
+    return require_decoding(feature, ignore_decode_attribute=ignore_decode_attribute)
+
+
+def keep_features_dicts_synced(func):
+    """
+    Wrapper to keep the secondary dictionary, which tracks whether keys are decodable, of the :class:`datasets.Features` object
+    in sync with the main dictionary.
+    """
+
+    @wraps(func)
+    def wrapper(*args, **kwargs):
+        if args:
+            self: "Features" = args[0]
+            args = args[1:]
+        else:
+            self: "Features" = kwargs.pop("self")
+        out = func(self, *args, **kwargs)
+        assert hasattr(self, "_column_requires_decoding")
+        self._column_requires_decoding = {col: require_decoding(feature) for col, feature in self.items()}
+        return out
+
+    wrapper._decorator_name_ = "_keep_dicts_synced"
+    return wrapper
+
+
 class Features(dict):
     """A special dictionary that defines the internal structure of a dataset.
 
@@ -1234,26 +1275,73 @@ class Features(dict):
     def __init__(self, *args, **kwargs):
         super().__init__(*args, **kwargs)
         self._column_requires_decoding: Dict[str, bool] = {
-            col: require_decoding(feature) for col, feature in self.items()
+            col: custom_require_decoding(feature) for col, feature in self.items()
         }
 
-    def __setitem__(self, column_name: str, feature: FeatureType):
-        super().__setitem__(column_name, feature)
-        self._column_requires_decoding[column_name] = require_decoding(feature)
+    __setitem__ = keep_features_dicts_synced(dict.__setitem__)
+ 
+    def set_custom_decoding_criteria(self, custom_criteria: Optional[callable] = None):
+        """Allows setting custom criteria for decoding."""
+        self._column_requires_decoding = {
+            col: custom_require_decoding(feature, custom_criteria=custom_criteria) 
+            for col, feature in self.items()
+        }
 
-    def __delitem__(self, column_name: str):
-        super().__delitem__(column_name)
-        del self._column_requires_decoding[column_name]
+    __delitem__ = keep_features_dicts_synced(dict.__delitem__)
+ 
+    @keep_features_dicts_synced
+    def update(self, iterable=(), **kwds):
+        """
+        Extended update method that supports:
+        - mappings or iterables of (key, value) pairs
+        - parsing JSON strings that look like objects (start with "{")
+        - deep-merging dict values instead of overwriting existing dicts
+        """
 
-    def update(self, iterable, **kwds):
-        if hasattr(iterable, "keys"):
-            for key in iterable.keys():
-                self[key] = iterable[key]
-        else:
-            for key, value in iterable:
+        import json
+
+        def _coerce(value, key=None):
+            # Preserve original behavior: only try to parse if it's a JSON object-like string
+            if isinstance(value, str) and value.lstrip().startswith("{"):
+                try:
+                    return json.loads(value)
+                except json.JSONDecodeError:
+                    raise ValueError(f"Invalid JSON string for column: {key}")
+            return value
+
+        def _deep_update(dst: dict, src: dict):
+            for sk, sv in src.items():
+                if sk in dst and isinstance(dst[sk], dict) and isinstance(sv, dict):
+                    _deep_update(dst[sk], sv)
+                else:
+                    dst[sk] = sv
+
+        def _assign(key, value):
+            value = _coerce(value, key)
+            if key in self and isinstance(self[key], dict) and isinstance(value, dict):
+                _deep_update(self[key], value)
+            else:
                 self[key] = value
-        for key in kwds:
-            self[key] = kwds[key]
+
+        # Handle mappings and (key, value) iterables
+        if hasattr(iterable, "items"):
+            for k, v in iterable.items():
+                _assign(k, v)
+        elif hasattr(iterable, "keys"):
+            for k in iterable.keys():
+                _assign(k, iterable[k])
+        else:
+            for k, v in iterable:
+                _assign(k, v)
+
+        # Also apply **kwds with the same logic
+        for k, v in kwds.items():
+            _assign(k, v)
+
+    setdefault = keep_features_dicts_synced(dict.setdefault)
+    pop = keep_features_dicts_synced(dict.pop)
+    popitem = keep_features_dicts_synced(dict.popitem)
+    clear = keep_features_dicts_synced(dict.clear)
 
     def __reduce__(self):
         return Features, (dict(self),)
