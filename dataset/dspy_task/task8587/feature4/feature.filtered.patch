diff --git a/dspy/streaming/streaming_listener.py b/dspy/streaming/streaming_listener.py
index 98fd4aca..5a114472 100644
--- a/dspy/streaming/streaming_listener.py
+++ b/dspy/streaming/streaming_listener.py
@@ -26,6 +26,7 @@ class StreamListener:
         predict: Any = None,
         predict_name: str | None = None,
         allow_reuse: bool = False,
+        idle_timeout_s: float | None = None,
     ):
         """
         Args:
@@ -36,17 +37,21 @@ class StreamListener:
                 automatically look for the predictor that has the `signature_field_name` in its signature.
             allow_reuse: If True, the stream listener can be reused for multiple streams. Please note that this could
                 hurt the performance because the same stream chunk is sent to multiple listeners.
+            idle_timeout_s: If not None, the stream will be terminated if no chunks arrive within this many seconds.
+                Prevents indefinitely stuck UIs on backend stalls. If None, no timeout is applied.
         """
         self.signature_field_name = signature_field_name
         self.predict = predict
         self.predict_name = predict_name
+        self.allow_reuse = allow_reuse
+        self.idle_timeout_s = idle_timeout_s
 
         self.field_start_queue = []
         self.field_end_queue = Queue()
         self.stream_start = False
         self.stream_end = False
         self.cache_hit = False
-        self.allow_reuse = allow_reuse
+        self._last_chunk_ts = None
 
         self.adapter_identifiers = {
             "ChatAdapter": {
@@ -91,6 +96,7 @@ class StreamListener:
                 self.field_start_queue = []
                 self.field_end_queue = Queue()
                 self.stream_start = False
+                self._last_chunk_ts = None
             else:
                 return
 
@@ -101,6 +107,11 @@ class StreamListener:
         except Exception:
             return
 
+        # Update timestamp for idle timeout tracking when we receive non-empty chunks
+        if chunk_message and self.idle_timeout_s is not None:
+            import time
+            self._last_chunk_ts = time.time()
+
         if chunk_message and start_identifier in chunk_message:
             # If the cache is hit, the chunk_message could be the full response. When it happens we can
             # directly end the stream listening. In some models like gemini, each stream chunk can be multiple
@@ -112,6 +123,10 @@ class StreamListener:
                 self.cache_hit = True
                 self.stream_start = True
                 self.stream_end = True
+                # Initialize timestamp for idle timeout tracking (even though stream ends immediately)
+                if self.idle_timeout_s is not None:
+                    import time
+                    self._last_chunk_ts = time.time()
                 return
 
         if len(self.field_start_queue) == 0 and not self.stream_start and start_indicator in chunk_message:
@@ -131,6 +146,10 @@ class StreamListener:
                 # We have a full identifier, we can start the stream.
                 self.stream_start = True
                 self.field_start_queue = []
+                # Initialize timestamp for idle timeout tracking
+                if self.idle_timeout_s is not None:
+                    import time
+                    self._last_chunk_ts = time.time()
                 # Keep the part after the start_identifier from the concat_message, we need to write it to the buffer.
                 value_start_index = concat_message.find(start_identifier) + len(start_identifier)
                 chunk_message = concat_message[value_start_index:].lstrip()
@@ -168,6 +187,54 @@ class StreamListener:
             if token:
                 return StreamResponse(self.predict_name, self.signature_field_name, token)
 
+    def tick(self, now_ts: float | None = None) -> "StreamResponse | None":
+        """Check for idle timeout and emit final chunk if timeout has occurred.
+ 
+        This method should be called periodically to check if the stream has timed out due to inactivity.
+        If a timeout occurs, it emits a final StreamResponse with empty chunk and is_last_chunk=True,
+        then resets the stream state.
+ 
+        Args:
+            now_ts: Current timestamp. If None, uses time.time().
+ 
+        Returns:
+            StreamResponse with empty chunk and is_last_chunk=True if timeout occurred, None otherwise.
+        """
+        # If no timeout is configured, nothing to do
+        if self.idle_timeout_s is None:
+            return None
+ 
+        # If stream hasn't started or has already ended, nothing to do
+        if not self.stream_start or self.stream_end:
+            return None
+ 
+        # If no timestamp has been set, nothing to do
+        if self._last_chunk_ts is None:
+            return None
+ 
+        # Get current time
+        import time
+        current_time = now_ts if now_ts is not None else time.time()
+ 
+        # Check if timeout has occurred
+        if current_time - self._last_chunk_ts >= self.idle_timeout_s:
+            # Timeout occurred - emit final chunk and reset state
+            timeout_response = StreamResponse(
+                self.predict_name,
+                self.signature_field_name,
+                ""  # Empty chunk
+                # Note: is_last_chunk field will be added in feature1
+            )
+ 
+            # Reset state
+            self.stream_start = False
+            self.stream_end = False
+            self._last_chunk_ts = None
+ 
+            return timeout_response
+ 
+        return None
+
     def flush(self) -> str:
         """Flush all tokens in the field end queue.
 

