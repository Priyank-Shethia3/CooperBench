diff --git a/dspy/streaming/messages.py b/dspy/streaming/messages.py
index 9a73f19b8..1d9c68104 100644
--- a/dspy/streaming/messages.py
+++ b/dspy/streaming/messages.py
@@ -14,6 +14,7 @@ class StreamResponse:
     predict_name: str
     signature_field_name: str
     chunk: str
+    buffer_watermark: int
 
 
 @dataclass
diff --git a/dspy/streaming/streaming_listener.py b/dspy/streaming/streaming_listener.py
index 98fd4aca7..ca949bd99 100644
--- a/dspy/streaming/streaming_listener.py
+++ b/dspy/streaming/streaming_listener.py
@@ -26,6 +26,7 @@ class StreamListener:
         predict: Any = None,
         predict_name: str | None = None,
         allow_reuse: bool = False,
+        end_buffer_size: int = 10,
     ):
         """
         Args:
@@ -36,10 +37,20 @@ class StreamListener:
                 automatically look for the predictor that has the `signature_field_name` in its signature.
             allow_reuse: If True, the stream listener can be reused for multiple streams. Please note that this could
                 hurt the performance because the same stream chunk is sent to multiple listeners.
+            end_buffer_size: The size of the look-behind buffer used for end-marker detection. Must be between 3 and 64.
+                Smaller values reduce latency but may miss end markers, larger values are more robust but increase latency.
+                Defaults to 10 for backward compatibility.
         """
+        # Validate end_buffer_size bounds
+        if end_buffer_size < 3:
+            raise ValueError("end_buffer_size must be at least 3")
+        if end_buffer_size > 64:
+            raise ValueError("end_buffer_size must be at most 64")
+ 
         self.signature_field_name = signature_field_name
         self.predict = predict
         self.predict_name = predict_name
+        self.end_buffer_size = end_buffer_size
 
         self.field_start_queue = []
         self.field_end_queue = Queue()
@@ -152,10 +163,10 @@ class StreamListener:
             # The stream is started, we keep returning the token until we see the start of the next field.
             token = None
             self.field_end_queue.put(chunk_message)
-            if self.field_end_queue.qsize() > 10:
-                # We keep the last 10 tokens in the buffer to check if they form a valid identifier for end_identifier,
+            if self.field_end_queue.qsize() > self.end_buffer_size:
+                # We keep the last end_buffer_size tokens in the buffer to check if they form a valid identifier for end_identifier,
                 # i.e., "[[ ## {next_field_name} ## ]]" for ChatAdapter to identify the end of the current field.
-                # In most cases 10 tokens are enough to cover the end_identifier for all adapters.
+                # In most cases end_buffer_size tokens are enough to cover the end_identifier for all adapters.
                 token = self.field_end_queue.get()
             concat_message = "".join(self.field_end_queue.queue).strip()
             if re.search(end_identifier, concat_message):
@@ -166,14 +177,20 @@ class StreamListener:
                 token = token.rstrip()  # Remove the trailing \n\n
 
             if token:
-                return StreamResponse(self.predict_name, self.signature_field_name, token)
+                return StreamResponse(
+                    self.predict_name, 
+                    self.signature_field_name, 
+                    token,
+                    buffer_watermark=min(self.field_end_queue.qsize(), self.end_buffer_size)
+                )
 
     def flush(self) -> str:
         """Flush all tokens in the field end queue.
 
-        This method is called to flush out the last a few tokens when the stream is ended. These tokens
+        This method is called to flush out the last few tokens when the stream is ended. These tokens
         are in the buffer because we don't directly yield the tokens received by the stream listener
         with the purpose to not yield the end_identifier tokens, e.g., "[[ ## ... ## ]]" for ChatAdapter.
+        The buffer size is controlled by the end_buffer_size parameter.
         """
         last_tokens = "".join(self.field_end_queue.queue)
         self.field_end_queue = Queue()

