diff --git a/dspy/streaming/streaming_listener.py b/dspy/streaming/streaming_listener.py
index 98fd4aca..02bdb3d4 100644
--- a/dspy/streaming/streaming_listener.py
+++ b/dspy/streaming/streaming_listener.py
@@ -1,7 +1,7 @@
 import re
 from collections import defaultdict
 from queue import Queue
-from typing import TYPE_CHECKING, Any
+from typing import TYPE_CHECKING, Any, Callable
 
 from litellm import ModelResponseStream
 
@@ -26,6 +26,7 @@ class StreamListener:
         predict: Any = None,
         predict_name: str | None = None,
         allow_reuse: bool = False,
+        on_chunk: Callable[[StreamResponse], None] | None = None,
     ):
         """
         Args:
@@ -36,17 +37,21 @@ class StreamListener:
                 automatically look for the predictor that has the `signature_field_name` in its signature.
             allow_reuse: If True, the stream listener can be reused for multiple streams. Please note that this could
                 hurt the performance because the same stream chunk is sent to multiple listeners.
+            on_chunk: Optional callback function that will be called after each StreamResponse is created.
+                The callback receives the StreamResponse object and should not return anything.
+                Exceptions in the callback are swallowed with a warning to avoid breaking streams.
         """
         self.signature_field_name = signature_field_name
         self.predict = predict
         self.predict_name = predict_name
+        self.allow_reuse = allow_reuse
+        self.on_chunk = on_chunk
 
         self.field_start_queue = []
         self.field_end_queue = Queue()
         self.stream_start = False
         self.stream_end = False
         self.cache_hit = False
-        self.allow_reuse = allow_reuse
 
         self.adapter_identifiers = {
             "ChatAdapter": {
@@ -72,6 +77,11 @@ class StreamListener:
                 return True
         return False
 
+    def _call_on_chunk_callback(self, response: StreamResponse) -> None:
+        """Call the on_chunk callback if set."""
+        if self.on_chunk is not None:
+            self.on_chunk(response)
+
     def receive(self, chunk: ModelResponseStream):
         adapter_name = settings.adapter.__class__.__name__ if settings.adapter else "ChatAdapter"
         if adapter_name not in self.adapter_identifiers:
@@ -166,7 +176,9 @@ class StreamListener:
                 token = token.rstrip()  # Remove the trailing \n\n
 
             if token:
-                return StreamResponse(self.predict_name, self.signature_field_name, token)
+                response = StreamResponse(self.predict_name, self.signature_field_name, token)
+                self._call_on_chunk_callback(response)
+                return response
 
     def flush(self) -> str:
         """Flush all tokens in the field end queue.

