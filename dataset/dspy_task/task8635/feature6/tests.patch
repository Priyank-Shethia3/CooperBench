diff --git a/tests/propose/test_grounded_proposer6.py b/tests/propose/test_grounded_proposer6.py
new file mode 100644
index 00000000..cc658527
--- /dev/null
+++ b/tests/propose/test_grounded_proposer6.py
@@ -0,0 +1,142 @@
+import pytest
+
+import dspy
+from dspy.predict import Predict
+from dspy.propose.grounded_proposer import GroundedProposer
+from dspy.utils.dummies import DummyLM
+
+# Test cases for instruction length bounds feature
+def test_short_instruction_fallback():
+    """Test (a): short instruction handling - should fall back to basic_instruction"""
+    # Mock a very short instruction
+    prompt_model = DummyLM([{"proposed_instruction": "Hi"}] * 10)
+    program = Predict("question -> answer")
+ 
+    proposer = GroundedProposer(
+        prompt_model=prompt_model, 
+        program=program, 
+        trainset=[], 
+        min_instr_chars=30,
+        verbose=True
+    )
+ 
+    result = proposer.propose_instruction_for_predictor(
+        program=program,
+        predictor=None,
+        pred_i=0,
+        T=0.5,
+        demo_candidates=None,
+        demo_set_i=0,
+        trial_logs={},
+        tip=None,
+    )
+ 
+    # Should fall back to basic instruction (which is "question -> answer")
+    assert result == "Given the fields `question`, produce the fields `answer`."
+
+
+def test_long_instruction_trimming():
+    """Test (b): long instruction trimming - should trim at sentence boundary and add ..."""
+    # Mock a very long instruction
+    long_instruction = "This is a very long instruction that goes on and on. It has multiple sentences. It should be trimmed at a sentence boundary. This is the end."
+    prompt_model = DummyLM([{"proposed_instruction": long_instruction}] * 10)
+    program = Predict("question -> answer")
+ 
+    proposer = GroundedProposer(
+        prompt_model=prompt_model, 
+        program=program, 
+        trainset=[], 
+        max_instr_chars=100,
+        rephrase_when_too_long=False,
+        verbose=True
+    )
+ 
+    result = proposer.propose_instruction_for_predictor(
+        program=program,
+        predictor=None,
+        pred_i=0,
+        T=0.5,
+        demo_candidates=None,
+        demo_set_i=0,
+        trial_logs={},
+        tip=None,
+    )
+ 
+    # Should be trimmed at sentence boundary and end with the single-character ellipsis
+    assert len(result) <= 100
+    assert result.endswith("â€¦")
+
+
+def test_long_instruction_rephrasing():
+    """Test (c): long instruction rephrasing - should make one LM call to shorten"""
+    # Mock a very long instruction
+    long_instruction = "This is a very long instruction that goes on and on. It has multiple sentences. It should be rephrased to be more concise. This is the end."
+    # First call returns long instruction, second call returns shortened version
+    prompt_model = DummyLM([
+        {"proposed_instruction": long_instruction},
+        {"proposed_instruction": "Shortened concise instruction."}
+    ] * 10)
+    program = Predict("question -> answer")
+ 
+    proposer = GroundedProposer(
+        prompt_model=prompt_model, 
+        program=program, 
+        trainset=[], 
+        max_instr_chars=100,
+        rephrase_when_too_long=True,
+        verbose=True
+    )
+ 
+    result = proposer.propose_instruction_for_predictor(
+        program=program,
+        predictor=None,
+        pred_i=0,
+        T=0.5,
+        demo_candidates=None,
+        demo_set_i=0,
+        trial_logs={},
+        tip=None,
+    )
+ 
+    # Should be the shortened version (extracted from DummyLM response)
+    assert "Shortened concise instruction" in result
+    assert len(result) <= 100
+
+
+def test_instruction_length_bounds_defaults():
+    """Test that default parameters work correctly"""
+    prompt_model = DummyLM([{"proposed_instruction": "Normal length instruction"}] * 10)
+    program = Predict("question -> answer")
+ 
+    proposer = GroundedProposer(
+        prompt_model=prompt_model, 
+        program=program, 
+        trainset=[], 
+        verbose=False
+    )
+ 
+    # Should use default values
+    assert proposer.min_instr_chars == 30
+    assert proposer.max_instr_chars == 600
+    assert proposer.rephrase_when_too_long == False
+
+
+def test_instruction_length_bounds_custom_params():
+    """Test that custom parameters are properly set"""
+    prompt_model = DummyLM([{"proposed_instruction": "Normal length instruction"}] * 10)
+    program = Predict("question -> answer")
+ 
+    proposer = GroundedProposer(
+        prompt_model=prompt_model, 
+        program=program, 
+        trainset=[], 
+        min_instr_chars=50,
+        max_instr_chars=300,
+        rephrase_when_too_long=True,
+        verbose=False
+    )
+ 
+    # Should use custom values
+    assert proposer.min_instr_chars == 50
+    assert proposer.max_instr_chars == 300
+    assert proposer.rephrase_when_too_long == True
diff --git a/tests/propose/test_grounded_proposer.py b/tests/propose/test_grounded_proposer.py
index 252afe8a..6a947c27 100644
--- a/tests/propose/test_grounded_proposer.py
+++ b/tests/propose/test_grounded_proposer.py
@@ -26,7 +26,8 @@ def test_propose_instructions_for_program(demo_candidates):
     assert isinstance(result, dict)
     assert len(result) == len(program.predictors())
     for pred_instructions in result.values():
-        assert pred_instructions == ["instruction"]
+        # Now the instruction is processed through length bounds, so it should be the signature's default instruction
+        assert pred_instructions == ["Given the fields `question`, produce the fields `answer`."]
 
 
 @pytest.mark.parametrize(
@@ -51,4 +52,5 @@ def test_propose_instruction_for_predictor(demo_candidates):
         trial_logs={},
         tip=None,
     )
-    assert result == "instruction"
+    # Now the instruction is processed through length bounds, so it should be the signature's default instruction
+    assert result == "Given the fields `question`, produce the fields `answer`."
\ No newline at end of file
