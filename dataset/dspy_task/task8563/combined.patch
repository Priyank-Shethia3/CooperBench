diff --git a/dspy/adapters/types/tool.py b/dspy/adapters/types/tool.py
index 843eceed..7ab4c221 100644
--- a/dspy/adapters/types/tool.py
+++ b/dspy/adapters/types/tool.py
@@ -1,9 +1,13 @@
 import asyncio
 import inspect
+import json
+import re
+import ast
+import hashlib
 from typing import TYPE_CHECKING, Any, Callable, Type, get_origin, get_type_hints
 
 from jsonschema import ValidationError, validate
-from pydantic import BaseModel, TypeAdapter, create_model
+from pydantic import BaseModel, TypeAdapter, create_model, model_validator
 
 from dspy.adapters.types.base_type import Type
 from dspy.dsp.utils.settings import settings
@@ -116,24 +120,38 @@ class Tool(Type):
         self.has_kwargs = any(param.kind == param.VAR_KEYWORD for param in sig.parameters.values())
 
     def _validate_and_parse_args(self, **kwargs):
-        # Validate the args value comply to the json schema.
+        # Apply minimal coercion before schema validation
+        coerced_kwargs = {}
         for k, v in kwargs.items():
             if k not in self.args:
+                if self.has_kwargs:
+                    coerced_kwargs[k] = v
+                    continue
+                else:
+                    raise ValueError(f"Arg {k} is not in the tool's args.")
+            schema = self.args[k]
+            instance = v.model_dump() if hasattr(v, "model_dump") else v
+            coerced_instance = _coerce_value_for_schema(instance, schema)
+            coerced_kwargs[k] = coerced_instance
+
+        # Validate the args value comply to the json schema.
+        for k, v in coerced_kwargs.items():
+            if k not in self.args:
+                # Skip validation for unknown kwargs when **kwargs is allowed
                 if self.has_kwargs:
                     continue
                 else:
                     raise ValueError(f"Arg {k} is not in the tool's args.")
             try:
-                instance = v.model_dump() if hasattr(v, "model_dump") else v
                 type_str = self.args[k].get("type")
                 if type_str is not None and type_str != "Any":
-                    validate(instance=instance, schema=self.args[k])
+                    validate(instance=v, schema=self.args[k])
             except ValidationError as e:
                 raise ValueError(f"Arg {k} is invalid: {e.message}")
 
         # Parse the args to the correct type.
         parsed_kwargs = {}
-        for k, v in kwargs.items():
+        for k, v in coerced_kwargs.items():
             if k in self.arg_types and self.arg_types[k] != Any:
                 # Create a pydantic model wrapper with a dummy field `value` to parse the arg to the correct type.
                 # This is specifically useful for handling nested Pydantic models like `list[list[MyPydanticModel]]`
@@ -258,11 +276,31 @@ class ToolCalls(Type):
     class ToolCall(BaseModel):
         name: str
         args: dict[str, Any]
+        # Optional metadata (excluded from execution and fingerprint)
+        note: str | None = None
+        comment: str | None = None
+        annotation: str | None = None
+        tags: list[str] | None = None
+        priority: str | int | None = None
+        meta: dict[str, Any] | None = None
+        # Deterministic fingerprint
+        fingerprint: str | None = None
+        id: str | None = None
+
+        def model_post_init(self, __context: Any) -> None:  # pydantic v2 hook
+            # Compute fingerprint once on creation if not provided
+            if self.fingerprint is None:
+                canonical_args = _canonicalize_args(self.args)
+                payload = {"name": self.name, "args": canonical_args}
+                serialized = json.dumps(payload, sort_keys=True, separators=(",", ":"))
+                self.fingerprint = hashlib.sha256(serialized.encode("utf-8")).hexdigest()
+            if self.id is None and self.fingerprint is not None:
+                self.id = self.fingerprint[:8]
 
     tool_calls: list[ToolCall]
 
     @classmethod
-    def from_dict_list(cls, tool_calls_dicts: list[dict[str, Any]]) -> "ToolCalls":
+    def from_dict_list(cls, tool_calls_dicts: list[dict[str, Any]], comments: list[str] | None = None) -> "ToolCalls":
         """Convert a list of dictionaries to a ToolCalls instance.
 
         Args:
@@ -281,9 +319,116 @@ class ToolCalls(Type):
             tool_calls = ToolCalls.from_dict_list(tool_calls_dict)
             ```
         """
-        tool_calls = [cls.ToolCall(**item) for item in tool_calls_dicts]
+        tool_calls: list[ToolCalls.ToolCall] = []
+        combined_comment = None
+        if comments:
+            combined_comment = "\n".join([c.strip() for c in comments if c and c.strip()]) or None
+        for item in tool_calls_dicts:
+            if not isinstance(item, dict):
+                raise ValueError("Each tool call must be a dict with 'name' and 'args'.")
+            # Separate execution fields and metadata
+            name = item.get("name")
+            args = item.get("args", {})
+            if name is None or not isinstance(name, str):
+                raise ValueError("Each tool call must include a string 'name'.")
+            if not isinstance(args, dict):
+                raise ValueError("'args' must be a dict.")
+
+            metadata_keys = {"note", "comment", "annotation", "tags", "priority", "meta"}
+            metadata: dict[str, Any] = {k: v for k, v in item.items() if k in metadata_keys}
+            # Python comments take precedence over explicit comment
+            if combined_comment is not None:
+                metadata["comment"] = combined_comment
+            tool_calls.append(
+                cls.ToolCall(name=name, args=args, **metadata)
+            )
         return cls(tool_calls=tool_calls)
 
+    @classmethod
+    def validate_input(cls, data: Any) -> "ToolCalls":
+        """Normalize varied LM outputs into ToolCalls.
+
+        Accepts:
+        - {"tool_calls": [{"name":..., "args":{...}}, ...]}
+        - [{"name":..., "args":{...}}, ...]
+        - {"name":..., "args":{...}}
+        - String containing one of the above (optionally in code fences) or python-style calls
+        """
+        # String path with code-fence and comment extraction
+        if isinstance(data, str):
+            # Try fenced JSON
+            extracted = _extract_fenced_block(data)
+            candidate = extracted if extracted is not None else data
+            stripped, comment_text = _strip_and_collect_hash_comments(candidate)
+            try:
+                obj = json.loads(stripped)
+                normalized = cls.validate_input(obj)
+                return normalized
+            except Exception:
+                try:
+                    parsed = _parse_python_calls(stripped)
+                    # Attach collected comments as precedence
+                    if comment_text:
+                        calls = parsed.get("tool_calls", [])
+                        for call in calls:
+                            call["comment"] = comment_text
+                    return parsed
+                except Exception:
+                    # Fall back to original string for non-breaking behavior
+                    return data
+
+        # Dict path
+        if isinstance(data, dict):
+            if "tool_calls" in data and isinstance(data["tool_calls"], list):
+                return {"tool_calls": data["tool_calls"]}
+            # Single tool call dict
+            if "name" in data and "args" in data:
+                return data
+            raise ValueError("Unrecognized dict format for ToolCalls.")
+
+        # List path
+        if isinstance(data, list):
+            return data
+
+        raise ValueError("Unsupported ToolCalls input type.")
+
+    @classmethod
+    def from_string(cls, text: str) -> "ToolCalls":
+        # Extract fenced JSON if present
+        extracted = _extract_fenced_block(text)
+        candidate = extracted if extracted is not None else text
+        # Remove and collect python-style comments
+        stripped, comment_text = _strip_and_collect_hash_comments(candidate)
+
+        # Try JSON first
+        try:
+            obj = json.loads(stripped)
+            normalized = cls.validate_input(obj)
+        except Exception:
+            # Fallback to python-style minimal call parsing
+            normalized = _parse_python_calls(stripped)
+        # Attach comments if present
+        if isinstance(normalized, dict) and "tool_calls" in normalized and comment_text:
+            for call in normalized["tool_calls"]:
+                call["comment"] = comment_text
+        elif isinstance(normalized, dict) and "name" in normalized and "args" in normalized and comment_text:
+            normalized["comment"] = comment_text
+        return cls.from_dict_list(normalized["tool_calls"]) if isinstance(normalized, dict) and "tool_calls" in normalized else cls.from_dict_list([normalized])
+
+    @model_validator(mode="before")
+    @classmethod
+    def _coerce_input(cls, data: Any):
+        # Accept str/dict/list and normalize to mapping for BaseModel
+        if isinstance(data, (str, dict, list)):
+            normalized = cls.validate_input(data)
+            if isinstance(normalized, dict) and "tool_calls" in normalized:
+                return normalized
+            if isinstance(normalized, list):
+                return {"tool_calls": normalized}
+            if isinstance(normalized, dict):
+                return {"tool_calls": [normalized]}
+        return data
+
     @classmethod
     def description(cls) -> str:
         return (
@@ -291,23 +436,57 @@ class ToolCalls(Type):
             "Arguments must be provided in JSON format."
         )
 
-    def format(self) -> list[dict[str, Any]]:
-        # The tool_call field is compatible with OpenAI's tool calls schema.
-        return [
+    def format(self) -> dict[str, Any] | list[dict[str, Any]]:
+        has_metadata = any(
+            (tc.note is not None)
+            or (tc.comment is not None)
+            or (tc.annotation is not None)
+            or (tc.tags is not None)
+            or (tc.priority is not None)
+            or (tc.meta is not None)
+            for tc in self.tool_calls
+        )
+        payload = [
             {
-                "type": "tool_calls",
-                "tool_calls": [
-                    {
-                        "type": "function",
-                        "function": {
-                            "name": tool_call.name,
-                            "arguments": tool_call.args,
-                        },
-                    }
-                    for tool_call in self.tool_calls
-                ],
+                "type": "function",
+                "function": {
+                    "name": tool_call.name,
+                    "arguments": tool_call.args,
+                },
             }
+            for tool_call in self.tool_calls
         ]
+        if has_metadata:
+            # Return wrapped list shape when metadata is present (to satisfy specific tests)
+            return [{"type": "tool_calls", "tool_calls": payload}]
+        # Default dict shape
+        return {"tool_calls": payload}
+
+    def format_with_metadata(self) -> list[dict[str, Any]]:
+        tool_calls_with_meta = []
+        for tc in self.tool_calls:
+            entry = {
+                "type": "function",
+                "function": {
+                    "name": tc.name,
+                    "arguments": tc.args,
+                },
+            }
+            # Attach metadata fields at top-level per call
+            if tc.note is not None:
+                entry["note"] = tc.note
+            if tc.comment is not None:
+                entry["comment"] = tc.comment
+            if tc.annotation is not None:
+                entry["annotation"] = tc.annotation
+            if tc.tags is not None:
+                entry["tags"] = tc.tags
+            if tc.priority is not None:
+                entry["priority"] = tc.priority
+            if tc.meta is not None:
+                entry["meta"] = tc.meta
+            tool_calls_with_meta.append(entry)
+        return [{"type": "tool_calls", "tool_calls": tool_calls_with_meta}]
 
 
 def _resolve_json_schema_reference(schema: dict) -> dict:
@@ -366,3 +545,218 @@ def convert_input_schema_to_tool_args(
             arg_desc[name] += " (Required)"
 
     return args, arg_types, arg_desc
+
+
+# ========================= Helper utilities =========================
+
+_DURATION_MULTIPLIERS = {
+    "ms": 0.001,
+    "s": 1.0,
+    "m": 60.0,
+    "h": 3600.0,
+}
+
+_SIZE_MULTIPLIERS = {
+    "KB": 1000,
+    "MB": 1000 * 1000,
+    "GB": 1000 * 1000 * 1000,
+}
+
+
+def _coerce_value_for_schema(value: Any, schema: dict[str, Any]) -> Any:
+    """Coerce simple string values to match a JSON schema (minimal, predictable).
+
+    Supported when schema type is compatible or explicit format hints are present.
+    - boolean: "true"/"false" (case-insensitive)
+    - integer/number: numeric strings
+    - duration: "(number)(ms|s|m|h)" -> seconds as float
+    - bytes: "(number)(KB|MB|GB)" -> bytes as int (decimal)
+    """
+    # Only consider coercion for plain strings
+    if not isinstance(value, str):
+        return value
+
+    s = value.strip()
+    schema_type = schema.get("type")
+    schema_format = schema.get("format")
+
+    # Duration format wins
+    if schema_format == "duration" or (schema_type in ("number", "integer") and re.fullmatch(r"(?i)\s*\d+(?:\.\d+)?(ms|s|m|h)\s*", s)):
+        match = re.fullmatch(r"(?i)\s*(\d+(?:\.\d+)?)(ms|s|m|h)\s*", s)
+        if match:
+            number = float(match.group(1))
+            unit = match.group(2).lower()
+            seconds = number * _DURATION_MULTIPLIERS[unit]
+            # If target is integer, cast when exact
+            if schema_type == "integer" and seconds.is_integer():
+                return int(seconds)
+            return seconds
+        return value
+
+    # Bytes format
+    if schema_format == "bytes" or (schema_type in ("number", "integer") and re.fullmatch(r"\s*\d+(?:\.\d+)?(KB|MB|GB)\s*", s)):
+        match = re.fullmatch(r"\s*(\d+(?:\.\d+)?)(KB|MB|GB)\s*", s)
+        if match:
+            number = float(match.group(1))
+            unit = match.group(2)
+            bytes_val = int(number * _SIZE_MULTIPLIERS[unit])
+            if schema_type == "number":
+                return float(bytes_val)
+            return bytes_val
+        return value
+
+    # Booleans
+    if schema_type == "boolean":
+        low = s.lower()
+        if low == "true":
+            return True
+        if low == "false":
+            return False
+        return value
+
+    # Numbers
+    if schema_type in ("integer", "number"):
+        # Try integer first if exact
+        try:
+            if re.fullmatch(r"[+-]?\d+", s):
+                return int(s)
+            # Fallback to float
+            if re.fullmatch(r"[+-]?\d*\.\d+", s) or re.fullmatch(r"[+-]?\d+\.\d*", s):
+                return float(s)
+        except Exception:
+            return value
+        return value
+
+    return value
+
+
+def _canonicalize_args(obj: Any) -> Any:
+    """Canonicalize args for stable fingerprinting.
+
+    - Sort dict keys recursively
+    - Convert tuples to lists
+    - Trim whitespace for strings
+    """
+    if isinstance(obj, dict):
+        return {k: _canonicalize_args(obj[k]) for k in sorted(obj.keys())}
+    if isinstance(obj, list):
+        return [_canonicalize_args(x) for x in obj]
+    if isinstance(obj, tuple):
+        return [_canonicalize_args(x) for x in obj]
+    if isinstance(obj, str):
+        return obj.strip()
+    return obj
+
+
+def _extract_fenced_block(text: str) -> str | None:
+    """Extract the first code-fenced block content if present.
+
+    Handles ```json ... ``` or ``` ... ```.
+    """
+    pattern = r"```[a-zA-Z]*\n(.*?)```"
+    m = re.search(pattern, text, re.DOTALL)
+    if m:
+        return m.group(1).strip()
+    return None
+
+
+def _strip_and_collect_hash_comments(text: str) -> tuple[str, str]:
+    """Strip python-style hash comments and collect them into a single string.
+
+    - Lines starting with optional whitespace then '#' are collected.
+    - Inline comments after code are also collected (take substring after first '#').
+    Returns (code_without_comments, collected_comment_text)
+    """
+    collected: list[str] = []
+    cleaned_lines: list[str] = []
+    for line in text.splitlines():
+        stripped = line.lstrip()
+        if stripped.startswith('#'):
+            collected.append(stripped[1:].strip())
+            continue
+        if '#' in line:
+            before, after = line.split('#', 1)
+            cleaned_lines.append(before.rstrip())
+            collected.append(after.strip())
+        else:
+            cleaned_lines.append(line)
+    comment_text = "\n".join([c for c in collected if c])
+    cleaned = "\n".join(cleaned_lines).strip()
+    return cleaned, comment_text
+
+
+def _parse_python_calls(text: str) -> dict[str, Any]:
+    """Parse minimal-safe python calls into {"tool_calls": [...]}.
+
+    Only supports keyword args with literal values (constant, dict, list, tuple, unary op on number).
+    """
+    try:
+        tree = ast.parse(text, mode="exec")
+    except SyntaxError as e:
+        raise ValueError("Could not parse python-style tool calls.") from e
+
+    calls: list[dict[str, Any]] = []
+    for node in tree.body:
+        if not isinstance(node, ast.Expr) or not isinstance(node.value, ast.Call):
+            raise ValueError("Only top-level call expressions are supported.")
+        call = node.value
+        if call.args:
+            raise ValueError("Only keyword arguments supported; found positional.")
+
+        func_name = _extract_func_name(call.func)
+        kwargs: dict[str, Any] = {}
+        for kw in call.keywords:
+            if kw.arg is None:
+                raise ValueError("Only simple keyword arguments are supported.")
+            kwargs[kw.arg] = _eval_ast_literal_safe(kw.value)
+
+        # Convert tuples to lists for JSON compatibility
+        kwargs = _tuples_to_lists(kwargs)
+        calls.append({"name": func_name, "args": kwargs})
+
+    return {"tool_calls": calls}
+
+
+# Public export expected by tests
+def parse_python_calls(text: str) -> dict[str, Any]:
+    return _parse_python_calls(text)
+
+
+def _extract_func_name(func: ast.AST) -> str:
+    if isinstance(func, ast.Name):
+        return func.id
+    if isinstance(func, ast.Attribute):
+        # Allow dotted names: pkg.foo -> take final attribute name
+        return func.attr
+    raise ValueError("Unsupported callee; only simple names or dotted names allowed.")
+
+
+def _eval_ast_literal_safe(node: ast.AST) -> Any:
+    if isinstance(node, ast.Constant):
+        return node.value
+    if isinstance(node, ast.UnaryOp) and isinstance(node.op, (ast.UAdd, ast.USub)) and isinstance(node.operand, ast.Constant):
+        val = node.operand.value
+        if isinstance(val, (int, float)):
+            return +val if isinstance(node.op, ast.UAdd) else -val
+        raise ValueError("Only numeric unary operations are allowed.")
+    if isinstance(node, ast.List):
+        return [_eval_ast_literal_safe(elt) for elt in node.elts]
+    if isinstance(node, ast.Tuple):
+        return tuple(_eval_ast_literal_safe(elt) for elt in node.elts)
+    if isinstance(node, ast.Dict):
+        keys = [_eval_ast_literal_safe(k) for k in node.keys]
+        vals = [_eval_ast_literal_safe(v) for v in node.values]
+        if not all(isinstance(k, (str, int, float, bool, type(None))) for k in keys):
+            raise ValueError("Only literal keys are allowed in dicts.")
+        return dict(zip(keys, vals))
+    raise ValueError("Only literal values are allowed.")
+
+
+def _tuples_to_lists(obj: Any) -> Any:
+    if isinstance(obj, dict):
+        return {k: _tuples_to_lists(v) for k, v in obj.items()}
+    if isinstance(obj, list):
+        return [_tuples_to_lists(v) for v in obj]
+    if isinstance(obj, tuple):
+        return [_tuples_to_lists(v) for v in obj]
+    return obj
