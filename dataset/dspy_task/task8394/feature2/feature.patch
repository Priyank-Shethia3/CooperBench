diff --git a/dspy/clients/__init__.py b/dspy/clients/__init__.py
index 52be745a..2b6953cd 100644
--- a/dspy/clients/__init__.py
+++ b/dspy/clients/__init__.py
@@ -33,6 +33,7 @@ def configure_cache(
     disk_size_limit_bytes: Optional[int] = DISK_CACHE_LIMIT,
     memory_max_entries: Optional[int] = 1000000,
     enable_litellm_cache: bool = False,
+    namespace: Optional[str] = None,
 ):
     """Configure the cache for DSPy.
 
@@ -43,6 +44,7 @@ def configure_cache(
         disk_size_limit_bytes: The size limit of the on-disk cache.
         memory_max_entries: The maximum number of entries in the in-memory cache.
         enable_litellm_cache: Whether to enable LiteLLM cache.
+        namespace: Optional namespace to set for the cache.
     """
     if enable_disk_cache and enable_litellm_cache:
         raise ValueError(
@@ -73,6 +75,10 @@ def configure_cache(
         disk_size_limit_bytes,
         memory_max_entries,
     )
+ 
+    # Set the namespace if provided
+    if namespace is not None:
+        dspy.cache.set_namespace(namespace)
 
 
 litellm.telemetry = False
diff --git a/dspy/clients/cache.py b/dspy/clients/cache.py
index bfa7dbde..b81ee38f 100644
--- a/dspy/clients/cache.py
+++ b/dspy/clients/cache.py
@@ -1,7 +1,9 @@
 import copy
+import contextvars
 import inspect
 import logging
 import threading
+from contextlib import contextmanager
 from functools import wraps
 from hashlib import sha256
 from typing import Any, Dict, Optional
@@ -14,6 +16,57 @@ from diskcache import FanoutCache
 
 logger = logging.getLogger(__name__)
 
+# Thread-local namespace storage using contextvars for DSPy thread safety
+_cache_namespace: contextvars.ContextVar[Optional[str]] = contextvars.ContextVar('cache_namespace', default=None)
+
+
+class NamespaceProperty:
+    """A property that can also be used as a context manager."""
+ 
+    def __get__(self, instance, owner):
+        if instance is None:
+            return self
+        # Return a NamespaceAccessor that provides both property access and context manager functionality
+        return NamespaceAccessor()
+ 
+    def __set__(self, instance, value):
+        _cache_namespace.set(value)
+
+
+class NamespaceAccessor:
+    """Provides both property access and context manager functionality for namespace."""
+ 
+    def __str__(self):
+        """Return current namespace as string."""
+        return str(_cache_namespace.get())
+ 
+    def __eq__(self, other):
+        """Compare current namespace with other value."""
+        return _cache_namespace.get() == other
+ 
+    def __call__(self, namespace: Optional[str]):
+        """When called, return a context manager."""
+        @contextmanager
+        def namespace_context():
+            # Get the current namespace
+            current_namespace = _cache_namespace.get()
+ 
+            # Set the new namespace
+            token = _cache_namespace.set(namespace)
+ 
+            try:
+                yield
+            finally:
+                # Restore the previous namespace
+                _cache_namespace.reset(token)
+ 
+        return namespace_context()
+ 
+    @property
+    def value(self):
+        """Get the actual namespace value."""
+        return _cache_namespace.get()
+
 
 class Cache:
     """DSPy Cache
@@ -94,7 +147,15 @@ class Cache:
                 return value
 
         params = {k: transform_value(v) for k, v in request.items() if k not in ignored_args_for_cache_key}
-        return sha256(ujson.dumps(params, sort_keys=True).encode()).hexdigest()
+        key = sha256(ujson.dumps(params, sort_keys=True).encode()).hexdigest()
+ 
+        # Apply namespace prefix if namespace is set
+        namespace = self.namespace.value
+        if namespace is not None:
+            ns_hash = sha256(namespace.encode()).hexdigest()[:8]
+            key = f"{ns_hash}:{key}"
+ 
+        return key
 
     def get(self, request: Dict[str, Any], ignored_args_for_cache_key: Optional[list[str]] = None) -> Any:
         try:
@@ -168,6 +229,13 @@ class Cache:
             with open(filepath, "rb") as f:
                 self.memory_cache = cloudpickle.load(f)
 
+    # Use the special property that can also be a context manager
+    namespace = NamespaceProperty()
+
+    def set_namespace(self, namespace: Optional[str]) -> None:
+        """Set the namespace for the current context."""
+        _cache_namespace.set(namespace)
+
 
 def request_cache(
     cache_arg_name: Optional[str] = None,
@@ -175,6 +243,7 @@ def request_cache(
     enable_memory_cache: bool = True,
     *,  # everything after this is keyword-only
     maxsize: Optional[int] = None,  # legacy / no-op
+    namespace: Optional[str] = None,
 ):
     """
     Decorator for applying caching to a function based on the request argument.
@@ -185,6 +254,7 @@ def request_cache(
         ignored_args_for_cache_key: A list of arguments to ignore when computing the cache key from the request.
         enable_memory_cache: Whether to enable in-memory cache at call time. If False, the memory cache will not be
             written to on new data.
+        namespace: Optional namespace to use for all cache operations within the decorated function.
     """
     ignored_args_for_cache_key = ignored_args_for_cache_key or ["api_key", "api_base", "base_url"]
     # Deprecation notice
@@ -221,38 +291,74 @@ def request_cache(
             import dspy
 
             cache = dspy.cache
-            modified_request = process_request(args, kwargs)
+ 
+            # If namespace is provided, use it as context for the entire function call
+            if namespace is not None:
+                with cache.namespace(namespace):
+                    modified_request = process_request(args, kwargs)
+
+                    # Retrieve from cache if available
+                    cached_result = cache.get(modified_request, ignored_args_for_cache_key)
 
-            # Retrieve from cache if available
-            cached_result = cache.get(modified_request, ignored_args_for_cache_key)
+                    if cached_result is not None:
+                        return cached_result
 
-            if cached_result is not None:
-                return cached_result
+                    # Otherwise, compute and store the result
+                    result = fn(*args, **kwargs)
+                    # `enable_memory_cache` can be provided at call time to avoid indefinite growth.
+                    cache.put(modified_request, result, ignored_args_for_cache_key, enable_memory_cache)
 
-            # Otherwise, compute and store the result
-            result = fn(*args, **kwargs)
-            # `enable_memory_cache` can be provided at call time to avoid indefinite growth.
-            cache.put(modified_request, result, ignored_args_for_cache_key, enable_memory_cache)
+                    return result
+            else:
+                modified_request = process_request(args, kwargs)
+
+                # Retrieve from cache if available
+                cached_result = cache.get(modified_request, ignored_args_for_cache_key)
+
+                if cached_result is not None:
+                    return cached_result
 
-            return result
+                # Otherwise, compute and store the result
+                result = fn(*args, **kwargs)
+                # `enable_memory_cache` can be provided at call time to avoid indefinite growth.
+                cache.put(modified_request, result, ignored_args_for_cache_key, enable_memory_cache)
+
+                return result
 
         @wraps(fn)
         async def async_wrapper(*args, **kwargs):
             import dspy
 
             cache = dspy.cache
-            modified_request = process_request(args, kwargs)
+ 
+            # If namespace is provided, use it as context for the entire function call
+            if namespace is not None:
+                with cache.namespace(namespace):
+                    modified_request = process_request(args, kwargs)
+
+                    # Retrieve from cache if available
+                    cached_result = cache.get(modified_request, ignored_args_for_cache_key)
+                    if cached_result is not None:
+                        return cached_result
+
+                    # Otherwise, compute and store the result
+                    result = await fn(*args, **kwargs)
+                    cache.put(modified_request, result, ignored_args_for_cache_key, enable_memory_cache)
+
+                    return result
+            else:
+                modified_request = process_request(args, kwargs)
 
-            # Retrieve from cache if available
-            cached_result = cache.get(modified_request, ignored_args_for_cache_key)
-            if cached_result is not None:
-                return cached_result
+                # Retrieve from cache if available
+                cached_result = cache.get(modified_request, ignored_args_for_cache_key)
+                if cached_result is not None:
+                    return cached_result
 
-            # Otherwise, compute and store the result
-            result = await fn(*args, **kwargs)
-            cache.put(modified_request, result, ignored_args_for_cache_key, enable_memory_cache)
+                # Otherwise, compute and store the result
+                result = await fn(*args, **kwargs)
+                cache.put(modified_request, result, ignored_args_for_cache_key, enable_memory_cache)
 
-            return result
+                return result
 
         if inspect.iscoroutinefunction(fn):
             return async_wrapper
