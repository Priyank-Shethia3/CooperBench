diff --git a/src/click/core.py b/src/click/core.py
index f57ada6..70996c2 100644
--- a/src/click/core.py
+++ b/src/click/core.py
@@ -15,7 +15,6 @@ from contextlib import ExitStack
 from functools import update_wrapper
 from gettext import gettext as _
 from gettext import ngettext
-from itertools import repeat
 from types import TracebackType
 
 from . import types
@@ -90,7 +89,18 @@ def _check_nested_chain(
 
 
 def batch(iterable: cabc.Iterable[V], batch_size: int) -> list[tuple[V, ...]]:
-    return list(zip(*repeat(iter(iterable), batch_size), strict=False))
+    """Split an iterable into batches of the specified size."""
+    iterator = iter(iterable)
+    result = []
+    while True:
+        chunk = tuple(next(iterator, None) for _ in range(batch_size))
+        if not chunk[0]:  # If the first element is None, we're done
+            break
+        # Filter out None values from the last incomplete batch
+        filtered_chunk = tuple(x for x in chunk if x is not None)
+        if filtered_chunk:
+            result.append(filtered_chunk)
+    return result
 
 
 @contextmanager
@@ -2499,6 +2509,10 @@ class Option(Parameter):
                      multiple times and recorded.  This is similar to ``nargs``
                      in how it works but supports arbitrary number of
                      arguments.
+    :param batch_size: If provided and ``multiple`` is ``True``, the option
+                       values will be yielded in batches of this size instead
+                       of all at once. This enables processing large datasets
+                       in smaller, memory-efficient chunks.
     :param count: this flag makes an option increment an integer.
     :param allow_from_autoenv: if this is enabled then the value of this
                                parameter will be pulled from an environment
@@ -2541,6 +2555,7 @@ class Option(Parameter):
         is_flag: bool | None = None,
         flag_value: t.Any | None = None,
         multiple: bool = False,
+        batch_size: int | None = None,
         count: bool = False,
         allow_from_autoenv: bool = True,
         type: types.ParamType | t.Any | None = None,
@@ -2636,6 +2651,7 @@ class Option(Parameter):
         self.show_default = show_default
         self.show_choices = show_choices
         self.show_envvar = show_envvar
+        self.batch_size = batch_size
 
         if __debug__:
             if deprecated and prompt:
@@ -2662,6 +2678,12 @@ class Option(Parameter):
                 if self.is_flag:
                     raise TypeError("'count' is not valid with 'is_flag'.")
 
+            if batch_size is not None:
+                if not multiple:
+                    raise TypeError("'batch_size' is only valid with 'multiple=True'.")
+                if not isinstance(batch_size, int) or batch_size <= 0:
+                    raise ValueError("'batch_size' must be a positive integer.")
+
     def to_info_dict(self) -> dict[str, t.Any]:
         info_dict = super().to_info_dict()
         info_dict.update(
@@ -2671,6 +2693,7 @@ class Option(Parameter):
             flag_value=self.flag_value,
             count=self.count,
             hidden=self.hidden,
+            batch_size=self.batch_size,
         )
         return info_dict
 
@@ -3032,6 +3055,28 @@ class Option(Parameter):
 
         return value, source
 
+    def process_value(self, ctx: Context, value: t.Any) -> t.Any:
+        """Process the value, applying batching if configured."""
+        value = super().process_value(ctx, value)
+
+        # Apply batching if batch_size is set and we have multiple values
+        if (
+            self.batch_size is not None
+            and self.multiple
+            and value is not None
+            and hasattr(value, "__iter__")
+            and not isinstance(value, (str, bytes))
+        ):
+            # Convert to list if it's a tuple to ensure we can batch it
+            if isinstance(value, tuple):
+                value = list(value)
+            # Return iterator of batches, or empty tuple if no values
+            if not value:
+                return ()
+            return batch(value, self.batch_size)
+
+        return value
+
 
 class Argument(Parameter):
     """Arguments are positional parameters to a command.  They generally
