diff --git a/tests/backends/test_xgrammar.py b/tests/backends/test_xgrammar.py
index 1133b9f0..c51f1085 100644
--- a/tests/backends/test_xgrammar.py
+++ b/tests/backends/test_xgrammar.py
@@ -1,4 +1,5 @@
 import pytest
+import torch
 
 import llama_cpp
 import transformers
@@ -93,3 +94,117 @@ def test_xgrammar_backend_invalid_model(model_llamacpp):
         match="The xgrammar backend only supports Transformers models",
     ):
         XGrammarBackend(model_llamacpp)
+
+
+# Batch size validation tests
+@pytest.fixture
+def compiled_grammar():
+    """Create a simple compiled grammar for testing."""
+    import xgrammar as xgr
+    from transformers import AutoTokenizer
+ 
+    tokenizer = AutoTokenizer.from_pretrained("erwanf/gpt2-mini")
+    tokenizer_info = xgr.TokenizerInfo.from_huggingface(tokenizer, vocab_size=50257)
+    compiler = xgr.GrammarCompiler(tokenizer_info)
+    return compiler.compile_regex(r"[0-9]{3}")
+
+
+def test_xgrammar_logits_processor_no_batch_limit(compiled_grammar):
+    """Test processor works normally without batch size limit."""
+    processor = XGrammarLogitsProcessor(compiled_grammar)
+    assert processor.max_batch_size is None
+ 
+    # Create mock tensors
+    input_ids = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])  # batch_size=3
+    logits = torch.randn(3, 50257)  # batch_size=3, vocab_size=50257
+ 
+    # Should not raise any error
+    result = processor.process_logits(input_ids, logits)
+    assert result.shape == logits.shape
+
+
+def test_xgrammar_logits_processor_batch_size_within_limit(compiled_grammar):
+    """Test processor works when batch size is within limit."""
+    processor = XGrammarLogitsProcessor(compiled_grammar, max_batch_size=5)
+    assert processor.max_batch_size == 5
+ 
+    # Create mock tensors with batch size within limit
+    input_ids = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])  # batch_size=3
+    logits = torch.randn(3, 50257)  # batch_size=3, vocab_size=50257
+ 
+    # Should not raise any error
+    result = processor.process_logits(input_ids, logits)
+    assert result.shape == logits.shape
+
+
+def test_xgrammar_logits_processor_batch_size_at_limit(compiled_grammar):
+    """Test processor works when batch size equals the limit."""
+    processor = XGrammarLogitsProcessor(compiled_grammar, max_batch_size=3)
+    assert processor.max_batch_size == 3
+ 
+    # Create mock tensors with batch size exactly at limit
+    input_ids = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])  # batch_size=3
+    logits = torch.randn(3, 50257)  # batch_size=3, vocab_size=50257
+ 
+    # Should not raise any error
+    result = processor.process_logits(input_ids, logits)
+    assert result.shape == logits.shape
+
+
+def test_xgrammar_logits_processor_batch_size_exceeds_limit(compiled_grammar):
+    """Test processor raises error when batch size exceeds limit."""
+    processor = XGrammarLogitsProcessor(compiled_grammar, max_batch_size=2)
+    assert processor.max_batch_size == 2
+ 
+    # Create mock tensors with batch size exceeding limit
+    input_ids = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])  # batch_size=3
+    logits = torch.randn(3, 50257)  # batch_size=3, vocab_size=50257
+ 
+    # Should raise ValueError
+    with pytest.raises(ValueError, match="Batch size 3 exceeds maximum allowed batch size 2"):
+        processor.process_logits(input_ids, logits)
+
+
+def test_xgrammar_logits_processor_single_batch(compiled_grammar):
+    """Test processor with single batch."""
+    processor = XGrammarLogitsProcessor(compiled_grammar, max_batch_size=1)
+ 
+    # Create mock tensors with single batch
+    input_ids = torch.tensor([[1, 2, 3]])  # batch_size=1
+    logits = torch.randn(1, 50257)  # batch_size=1, vocab_size=50257
+ 
+    # Should not raise any error
+    result = processor.process_logits(input_ids, logits)
+    assert result.shape == logits.shape
+
+
+def test_xgrammar_logits_processor_zero_batch_size_limit(compiled_grammar):
+    """Test processor with zero batch size limit."""
+    processor = XGrammarLogitsProcessor(compiled_grammar, max_batch_size=0)
+ 
+    # Any non-zero batch should fail
+    input_ids = torch.tensor([[1, 2, 3]])  # batch_size=1
+    logits = torch.randn(1, 50257)
+ 
+    with pytest.raises(ValueError, match="Batch size 1 exceeds maximum allowed batch size 0"):
+        processor.process_logits(input_ids, logits)
+
+
+def test_xgrammar_logits_processor_reset_revalidates(compiled_grammar):
+    """Test that reset allows revalidation on next call."""
+    processor = XGrammarLogitsProcessor(compiled_grammar, max_batch_size=2)
+ 
+    # First call with valid batch size
+    input_ids = torch.tensor([[1, 2, 3], [4, 5, 6]])  # batch_size=2
+    logits = torch.randn(2, 50257)
+    processor.process_logits(input_ids, logits)
+ 
+    # Reset the processor
+    processor.reset()
+ 
+    # Next call should validate again - this should fail
+    input_ids_large = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])  # batch_size=3
+    logits_large = torch.randn(3, 50257)
+ 
+    with pytest.raises(ValueError, match="Batch size 3 exceeds maximum allowed batch size 2"):
+        processor.process_logits(input_ids_large, logits_large)
