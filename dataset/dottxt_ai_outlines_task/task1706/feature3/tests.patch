diff --git a/tests/backends/test_xgrammar.py b/tests/backends/test_xgrammar.py
index 1133b9f0..de5767d5 100644
--- a/tests/backends/test_xgrammar.py
+++ b/tests/backends/test_xgrammar.py
@@ -93,3 +93,245 @@ def test_xgrammar_backend_invalid_model(model_llamacpp):
         match="The xgrammar backend only supports Transformers models",
     ):
         XGrammarBackend(model_llamacpp)
+
+
+def test_xgrammar_logits_processor_temperature_parameter():
+    """Test XGrammarLogitsProcessor temperature parameter initialization."""
+    import xgrammar as xgr
+ 
+    # Create a simple compiled grammar for testing
+    tokenizer_info = xgr.TokenizerInfo.from_huggingface(
+        transformers.AutoTokenizer.from_pretrained("erwanf/gpt2-mini"),
+        vocab_size=50257
+    )
+    grammar_compiler = xgr.GrammarCompiler(tokenizer_info)
+    compiled_grammar = grammar_compiler.compile_regex(r"[0-9]{3}")
+ 
+    # Test default temperature (1.0)
+    processor_default = XGrammarLogitsProcessor(compiled_grammar)
+    assert processor_default.temperature == 1.0
+ 
+    # Test custom temperature values
+    processor_low = XGrammarLogitsProcessor(compiled_grammar, temperature=0.5)
+    assert processor_low.temperature == 0.5
+ 
+    processor_high = XGrammarLogitsProcessor(compiled_grammar, temperature=2.0)
+    assert processor_high.temperature == 2.0
+ 
+    # Test zero temperature (edge case)
+    processor_zero = XGrammarLogitsProcessor(compiled_grammar, temperature=0.1)
+    assert processor_zero.temperature == 0.1
+
+
+def test_xgrammar_backend_temperature_methods(model_transformers, json_schema, regex, cfg):
+    """Test that backend methods accept temperature parameter."""
+    backend = XGrammarBackend(model_transformers)
+ 
+    # Test JSON schema processor with temperature
+    processor_json = backend.get_json_schema_logits_processor(json_schema, temperature=0.8)
+    assert isinstance(processor_json, XGrammarLogitsProcessor)
+    assert processor_json.temperature == 0.8
+ 
+    # Test regex processor with temperature
+    processor_regex = backend.get_regex_logits_processor(regex, temperature=1.5)
+    assert isinstance(processor_regex, XGrammarLogitsProcessor)
+    assert processor_regex.temperature == 1.5
+ 
+    # Test CFG processor with temperature
+    processor_cfg = backend.get_cfg_logits_processor(cfg, temperature=0.3)
+    assert isinstance(processor_cfg, XGrammarLogitsProcessor)
+    assert processor_cfg.temperature == 0.3
+
+
+def test_xgrammar_backend_temperature_defaults(model_transformers, json_schema, regex, cfg):
+    """Test that backend methods use default temperature when not specified."""
+    backend = XGrammarBackend(model_transformers)
+ 
+    # Test default temperature (should be 1.0)
+    processor_json = backend.get_json_schema_logits_processor(json_schema)
+    assert processor_json.temperature == 1.0
+ 
+    processor_regex = backend.get_regex_logits_processor(regex)
+    assert processor_regex.temperature == 1.0
+ 
+    processor_cfg = backend.get_cfg_logits_processor(cfg)
+    assert processor_cfg.temperature == 1.0
+
+
+def test_xgrammar_temperature_parameter_validation():
+    """Test temperature parameter validation and edge cases."""
+    import xgrammar as xgr
+ 
+    tokenizer_info = xgr.TokenizerInfo.from_huggingface(
+        transformers.AutoTokenizer.from_pretrained("erwanf/gpt2-mini"),
+        vocab_size=50257
+    )
+    grammar_compiler = xgr.GrammarCompiler(tokenizer_info)
+    compiled_grammar = grammar_compiler.compile_regex(r"[0-9]{3}")
+ 
+    # Test very small positive temperature
+    processor_small = XGrammarLogitsProcessor(compiled_grammar, temperature=0.01)
+    assert processor_small.temperature == 0.01
+ 
+    # Test large temperature
+    processor_large = XGrammarLogitsProcessor(compiled_grammar, temperature=10.0)
+    assert processor_large.temperature == 10.0
+ 
+    # Test temperature exactly 1.0 (no scaling)
+    processor_one = XGrammarLogitsProcessor(compiled_grammar, temperature=1.0)
+    assert processor_one.temperature == 1.0
+
+
+def test_xgrammar_processor_reset_with_temperature():
+    """Test that reset method works correctly with temperature parameter."""
+    import xgrammar as xgr
+ 
+    tokenizer_info = xgr.TokenizerInfo.from_huggingface(
+        transformers.AutoTokenizer.from_pretrained("erwanf/gpt2-mini"),
+        vocab_size=50257
+    )
+    grammar_compiler = xgr.GrammarCompiler(tokenizer_info)
+    compiled_grammar = grammar_compiler.compile_regex(r"[0-9]{3}")
+ 
+    processor = XGrammarLogitsProcessor(compiled_grammar, temperature=0.7)
+ 
+    # Temperature should persist after reset (behavioral requirement)
+    processor.reset()
+    assert processor.temperature == 0.7
+ 
+    # Verify processor still works after reset (functional behavior)
+    import torch
+    input_ids = torch.tensor([[1, 2, 3]], dtype=torch.long)
+    logits = torch.randn(1, 50257, dtype=torch.float32)
+    result = processor(input_ids, logits)
+    assert isinstance(result, torch.Tensor)
+    assert result.shape == logits.shape
+
+
+def test_xgrammar_temperature_error_conditions():
+    """Test error conditions and invalid temperature values."""
+    import xgrammar as xgr
+ 
+    tokenizer_info = xgr.TokenizerInfo.from_huggingface(
+        transformers.AutoTokenizer.from_pretrained("erwanf/gpt2-mini"),
+        vocab_size=50257
+    )
+    grammar_compiler = xgr.GrammarCompiler(tokenizer_info)
+    compiled_grammar = grammar_compiler.compile_regex(r"[0-9]{3}")
+ 
+    # Test negative temperature (should work but may not be practical)
+    processor_negative = XGrammarLogitsProcessor(compiled_grammar, temperature=-1.0)
+    assert processor_negative.temperature == -1.0
+ 
+    # Test zero temperature (edge case that should work)
+    processor_zero = XGrammarLogitsProcessor(compiled_grammar, temperature=0.0)
+    assert processor_zero.temperature == 0.0
+
+
+def test_xgrammar_temperature_integration(model_transformers):
+    """Integration test with temperature parameter in generation."""
+    backend = XGrammarBackend(model_transformers)
+ 
+    # Test with different temperature values
+    regex = r"[0-9]{3}"
+ 
+    # Low temperature (more focused)
+    processor_low = backend.get_regex_logits_processor(regex, temperature=0.1)
+    generator_low = outlines.Generator(model_transformers, backend="xgrammar", processor=processor_low)
+ 
+    # High temperature (more random)
+    processor_high = backend.get_regex_logits_processor(regex, temperature=2.0)
+    generator_high = outlines.Generator(model_transformers, backend="xgrammar", processor=processor_high)
+ 
+    # Both should still produce valid 3-digit numbers
+    response_low = generator_low("Generate a number: ")
+    response_high = generator_high("Generate a number: ")
+ 
+    assert len(response_low) == 3
+    assert len(response_high) == 3
+    assert int(response_low)  # Should be valid integer
+    assert int(response_high)  # Should be valid integer
+
+
+def test_xgrammar_temperature_boundary_values():
+    """Test boundary values for temperature parameter."""
+    import xgrammar as xgr
+ 
+    tokenizer_info = xgr.TokenizerInfo.from_huggingface(
+        transformers.AutoTokenizer.from_pretrained("erwanf/gpt2-mini"),
+        vocab_size=50257
+    )
+    grammar_compiler = xgr.GrammarCompiler(tokenizer_info)
+    compiled_grammar = grammar_compiler.compile_regex(r"[0-9]{3}")
+ 
+    # Test very small positive temperature
+    processor_tiny = XGrammarLogitsProcessor(compiled_grammar, temperature=1e-10)
+    assert processor_tiny.temperature == 1e-10
+ 
+    # Test very large temperature
+    processor_huge = XGrammarLogitsProcessor(compiled_grammar, temperature=1e10)
+    assert processor_huge.temperature == 1e10
+ 
+    # Test temperature close to 1.0 but not exactly 1.0
+    processor_close = XGrammarLogitsProcessor(compiled_grammar, temperature=1.0001)
+    assert processor_close.temperature == 1.0001
+
+
+def test_xgrammar_temperature_functional_behavior(model_transformers):
+    """Test that temperature parameter works functionally with grammar constraints."""
+    backend = XGrammarBackend(model_transformers)
+    regex = r"[0-9]{3}"
+ 
+    # Create processors with different temperatures
+    processor_default = backend.get_regex_logits_processor(regex, temperature=1.0)
+    processor_low_temp = backend.get_regex_logits_processor(regex, temperature=0.5)
+    processor_high_temp = backend.get_regex_logits_processor(regex, temperature=2.0)
+ 
+    # Test that processors can be used for actual generation (integration test)
+    # This tests functional behavior without making assumptions about internal implementation
+    generator_default = outlines.Generator(model_transformers, backend="xgrammar", processor=processor_default)
+    generator_low = outlines.Generator(model_transformers, backend="xgrammar", processor=processor_low_temp)
+    generator_high = outlines.Generator(model_transformers, backend="xgrammar", processor=processor_high_temp)
+ 
+    # All should produce valid outputs that satisfy the grammar constraint
+    response_default = generator_default("Generate a number: ")
+    response_low = generator_low("Generate a number: ")
+    response_high = generator_high("Generate a number: ")
+ 
+    # Test that grammar constraints are preserved (behavioral requirement)
+    assert len(response_default) == 3 and response_default.isdigit()
+    assert len(response_low) == 3 and response_low.isdigit()
+    assert len(response_high) == 3 and response_high.isdigit()
+ 
+    # Test that temperature values are correctly stored (API contract)
+    assert processor_default.temperature == 1.0
+    assert processor_low_temp.temperature == 0.5
+    assert processor_high_temp.temperature == 2.0
+
+
+def test_xgrammar_temperature_default_behavior(model_transformers):
+    """Test that temperature=1.0 produces correct functional behavior."""
+    backend = XGrammarBackend(model_transformers)
+    regex = r"[0-9]{3}"
+ 
+    # Create processor with default temperature (1.0)
+    processor = backend.get_regex_logits_processor(regex, temperature=1.0)
+ 
+    # Test functional behavior - should work correctly regardless of internal implementation
+    generator = outlines.Generator(model_transformers, backend="xgrammar", processor=processor)
+    response = generator("Generate a number: ")
+ 
+    # Verify correct behavior (API contract)
+    assert len(response) == 3
+    assert response.isdigit()
+    assert processor.temperature == 1.0
+ 
+    # Test that processor can be created and used multiple times (behavioral requirement)
+    # This tests the API contract without making assumptions about internal implementation
+    processor2 = backend.get_regex_logits_processor(regex, temperature=1.0)
+    generator2 = outlines.Generator(model_transformers, backend="xgrammar", processor=processor2)
+    response2 = generator2("Another number: ")
+ 
+    # Both should produce valid results
+    assert len(response2) == 3 and response2.isdigit()
+    assert processor2.temperature == 1.0
